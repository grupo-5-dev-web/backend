## White Label Resource Scheduling Platform ‚Äì Backend

A plataforma permite que diferentes neg√≥cios configurem regras pr√≥prias de agendamento (recursos humanos, equipamentos ou espa√ßos) utilizando a mesma base white label. O backend foi estruturado como um conjunto de microsservi√ßos FastAPI multi-tenant, com regras configur√°veis por organiza√ß√£o e propaga√ß√£o de eventos.

### Stack e diretrizes
- Python 3.11 + FastAPI em cada servi√ßo
- SQLAlchemy + PostgreSQL (um banco por dom√≠nio, suporte a JSONB)
- Alembic por servi√ßo para migra√ß√µes independentes
- Redis Streams para publica√ß√£o de eventos (pode evoluir para Kafka)
- Docker Compose para orquestra√ß√£o local
- Nginx como gateway reverso e landing page de documenta√ß√£o

### Estrutura do reposit√≥rio
```text
backend/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îî‚îÄ‚îÄ nginx/
‚îÇ       ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ       ‚îú‚îÄ‚îÄ nginx.conf
‚îÇ       ‚îî‚îÄ‚îÄ html/
‚îÇ           ‚îî‚îÄ‚îÄ index.html
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ shared/
    ‚îú‚îÄ‚îÄ tenant/
    ‚îú‚îÄ‚îÄ user/
    ‚îú‚îÄ‚îÄ resource/
    ‚îî‚îÄ‚îÄ booking/
```
- `services/shared`: utilidades comuns (config, mensageria, helpers de startup) copiadas para cada container.
- `services/<service>`: c√≥digo FastAPI isolado, com pastas `core`, `models`, `routers`, `schemas` e testes.
- `infra/nginx`: gateway que exp√µe os servi√ßos e disponibiliza uma landing page com links de Swagger.

> Execu√ß√£o local sem Docker: exporte `PYTHONPATH="$(pwd)/services/shared:$(pwd)/services/<servi√ßo>"` e rode `uvicorn app.main:app --reload` dentro da pasta do servi√ßo.

### Landing page e documenta√ß√£o
- `http://localhost:8000/` (gateway) exibe uma p√°gina com links para os Swagger UI de cada servi√ßo.
- Servi√ßos exp√µem documenta√ß√£o em:
	- `http://localhost:8000/api-docs/tenants` - Tenant Service (gerenciamento de organiza√ß√µes)
	- `http://localhost:8000/api-docs/users` - User Service (usu√°rios multi-tenant)
	- `http://localhost:8000/api-docs/resources` - Resource Service (categorias e recursos)
	- `http://localhost:8000/api-docs/bookings` - Booking Service (reservas e agendamentos)
- Cada endpoint documenta respostas de erro (400/404/409/422) alinhadas √†s regras de neg√≥cio.

### Servi√ßos e responsabilidades
- **tenant**: gerenciamento de tenants (organiza√ß√µes white label), configura√ß√µes de agendamento (`OrganizationSettings`), labels customizadas, hor√°rios comerciais e regras de anteced√™ncia/cancelamento.
- **resource**: categorias de recursos (f√≠sicos/humanos), recursos com atributos din√¢micos, disponibilidade di√°ria e c√°lculo de slots dispon√≠veis.
- **user**: perfis de usu√°rios multi-tenant, tipos (admin/user), permiss√µes granulares e metadados de perfil.
- **booking**: cria√ß√£o/atualiza√ß√£o/cancelamento de reservas com valida√ß√µes completas (conflitos de hor√°rio, janelas de anteced√™ncia, hor√°rio comercial, intervalo m√≠nimo) e emiss√£o de eventos em Redis Streams.

### Fluxos implementados
- **Regras de agendamento**: provider compartilhado (`services/shared/organization.py`) recupera `OrganizationSettings` do servi√ßo de tenant (HTTP via `httpx`) ou usa defaults. CRUD de bookings verifica hor√°rio √∫til, antecipa√ß√£o m√°xima, dura√ß√£o m√∫ltipla do intervalo e janela de cancelamento.
- **Timezone handling**: cada tenant configura seu timezone (ex: `America/Sao_Paulo`). Hor√°rios de entrada (API) sem timezone s√£o interpretados como hor√°rio local do tenant. Banco armazena tudo em UTC. Valida√ß√µes (hor√°rio comercial, disponibilidade) usam timezone do tenant. Cliente pode enviar hor√°rios em qualquer timezone (ISO 8601) e o sistema converte automaticamente.
- **Pol√≠tica de cancelamento**: listagens de reservas (`GET /bookings/`) incluem `can_cancel` calculado dinamicamente, refletindo a janela configurada pelo tenant.
- **Disponibilidade de recursos**: `GET /resources/{id}/availability` monta slots alinhados ao expediente e intervalo do tenant, consulta o servi√ßo de bookings via `BOOKING_SERVICE_URL` para bloquear conflitos e responde com timezone normalizado.
- **Detec√ß√£o de conflitos**: ao criar ou atualizar reservas, o sistema verifica se j√° existe booking aprovado/pendente no mesmo recurso e hor√°rio, retornando status 409 com lista de conflitos.
- **Arquitetura event-driven**: toda mudan√ßa de reserva (`booking.created`, `booking.updated`, `booking.cancelled`, `booking.status_changed`) √© publicada em Redis Streams. Servi√ßos de user e resource consomem eventos via Consumer Groups para atualizar caches, enviar notifica√ß√µes e registrar m√©tricas de forma ass√≠ncrona e desacoplada.
- **Landing page unificada**: gateway Nginx serve `http://localhost:8000/` com atalhos para a documenta√ß√£o Swagger de cada servi√ßo.

### Exemplo de fluxo completo
```bash
# 1. Criar tenant com regras de agendamento
curl -X POST http://localhost:8000/tenants/ -H "Content-Type: application/json" -d '{
  "name": "Academia Fit",
  "domain": "academia-fit.com",
  "logo_url": "https://exemplo.com/logo.png",
  "theme_primary_color": "#FF5722",
  "plan": "profissional",
  "settings": {
    "business_type": "fitness",
    "timezone": "America/Sao_Paulo",
    "working_hours_start": "06:00:00",
    "working_hours_end": "22:00:00",
    "booking_interval": 60,
    "advance_booking_days": 30,
    "cancellation_hours": 24,
    "custom_labels": {
      "resource_singular": "Sala",
      "resource_plural": "Salas",
      "booking_label": "Aula",
      "user_label": "Aluno"
    }
  }
}'
# Resposta: {"id": "d49eccff-6586-44cc-b723-719f78a6f9f9", ...}

# 2. Criar usu√°rio
curl -X POST http://localhost:8000/users/ -H "Content-Type: application/json" -d '{
  "tenant_id": "d49eccff-6586-44cc-b723-719f78a6f9f9",
  "name": "Jo√£o Silva",
  "email": "joao.silva@academiafit.com",
  "user_type": "user",
  "permissions": {"can_book": true}
}'
# Resposta: {"id": "6a899ad5-12bb-43ee-90ac-4d6f5091f6ae", ...}

# 3. Criar categoria de recurso
curl -X POST http://localhost:8000/categories/ -H "Content-Type: application/json" -d '{
  "tenant_id": "d49eccff-6586-44cc-b723-719f78a6f9f9",
  "name": "Salas de Aula",
  "description": "Espa√ßos para aulas coletivas",
  "type": "fisico",
  "icon": "room",
  "color": "#4CAF50"
}'
# Resposta: {"id": "6a37c359-0684-4e73-b86a-69afe164c7c9", ...}

# 4. Criar recurso
curl -X POST http://localhost:8000/resources/ -H "Content-Type: application/json" -d '{
  "tenant_id": "d49eccff-6586-44cc-b723-719f78a6f9f9",
  "category_id": "6a37c359-0684-4e73-b86a-69afe164c7c9",
  "name": "Sala 1 - Spinning",
  "description": "Sala equipada para aulas de spinning",
  "capacity": 20,
  "location": "Andar 2"
}'
# Resposta: {"id": "d4a90dee-9261-44df-a362-e6c12db591e2", ...}

# 5. Criar reserva v√°lida
curl -X POST http://localhost:8000/bookings/ -H "Content-Type: application/json" -d '{
  "tenant_id": "d49eccff-6586-44cc-b723-719f78a6f9f9",
  "resource_id": "d4a90dee-9261-44df-a362-e6c12db591e2",
  "user_id": "6a899ad5-12bb-43ee-90ac-4d6f5091f6ae",
  "client_id": "6a899ad5-12bb-43ee-90ac-4d6f5091f6ae",
  "start_time": "2025-12-05T14:00:00Z",
  "end_time": "2025-12-05T15:00:00Z",
  "notes": "Aula de Spinning - Iniciantes"
}'
# Resposta: {"id": "b6a2c6bc-5809-47ad-9aa7-6cf2adc35f42", "status": "pendente", ...}

# 6. Tentar criar reserva com conflito (retorna 409)
curl -X POST http://localhost:8000/bookings/ -H "Content-Type: application/json" -d '{
  "tenant_id": "d49eccff-6586-44cc-b723-719f78a6f9f9",
  "resource_id": "d4a90dee-9261-44df-a362-e6c12db591e2",
  "user_id": "6a899ad5-12bb-43ee-90ac-4d6f5091f6ae",
  "client_id": "6a899ad5-12bb-43ee-90ac-4d6f5091f6ae",
  "start_time": "2025-12-05T14:30:00Z",
  "end_time": "2025-12-05T15:30:00Z"
}'
# Resposta 409: {
#   "success": false,
#   "error": "conflict",
#   "message": "Recurso j√° possui reserva neste intervalo",
#   "conflicts": [{"booking_id": "b6a2c6bc-...", "start_time": "...", "end_time": "..."}]
# }

# 7. Listar reservas do tenant
curl "http://localhost:8000/bookings/?tenant_id=d49eccff-6586-44cc-b723-719f78a6f9f9"
# Resposta: [{"id": "...", "can_cancel": false, ...}]

# 8. Deletar recurso (cascata via evento resource.deleted)
curl -X DELETE http://localhost:8000/resources/d4a90dee-9261-44df-a362-e6c12db591e2
# ‚Üí Booking service cancela automaticamente todas as reservas daquele recurso

# 9. Deletar usu√°rio (cascata via evento user.deleted)
curl -X DELETE http://localhost:8000/users/6a899ad5-12bb-43ee-90ac-4d6f5091f6ae
# ‚Üí Booking service cancela automaticamente todas as reservas do usu√°rio

# 10. Deletar tenant (cascata via evento tenant.deleted)
curl -X DELETE http://localhost:8000/tenants/d49eccff-6586-44cc-b723-719f78a6f9f9
# ‚Üí User service deleta todos os usu√°rios do tenant
# ‚Üí Resource service deleta todos os recursos e categorias do tenant
# ‚Üí Booking service deleta todas as reservas do tenant
```

### Arquitetura Event-Driven com Redis Streams

O sistema implementa comunica√ß√£o ass√≠ncrona baseada em eventos usando **Redis Streams** com **Consumer Groups**, permitindo processamento distribu√≠do e garantias de entrega.

#### Componentes

**EventPublisher** (`services/shared/messaging.py`)
- Publica eventos no Redis Stream `booking-events`
- Cada evento cont√©m: `event_type`, `payload` (JSON) e `metadata` (tenant_id)
- Usado pelo Booking Service para emitir eventos ap√≥s mudan√ßas de estado

**EventConsumer** (`services/shared/event_consumer.py`)
- Consumidor gen√©rico baseado em `XREADGROUP` (Redis Streams)
- Suporta m√∫ltiplos consumidores no mesmo grupo para load balancing
- Processa mensagens pendentes no startup (recupera√ß√£o de falhas)
- Handlers registrados por tipo de evento
- Graceful shutdown com cancelamento de tasks asyncio

#### Eventos Publicados

**Stream: `booking-events`** (Booking Service)

| Evento | Payload | Quando |
|--------|---------|--------|
| `booking.created` | `booking_id`, `user_id`, `resource_id`, `status`, `start_time`, `end_time` | Nova reserva criada |
| `booking.updated` | `booking_id`, `resource_id`, `changes` (dict de mudan√ßas) | Reserva atualizada |
| `booking.cancelled` | `booking_id`, `resource_id`, `reason`, `cancelled_by` | Reserva cancelada |
| `booking.status_changed` | `booking_id`, `old_status`, `new_status` | Status alterado |

**Stream: `deletion-events`** (Cascata de dele√ß√µes)

| Evento | Payload | Quando | Efeito |
|--------|---------|--------|--------|
| `resource.deleted` | `resource_id`, `tenant_id` | Recurso deletado | Cancela todas as reservas do recurso |
| `user.deleted` | `user_id`, `tenant_id` | Usu√°rio deletado | Cancela todas as reservas do usu√°rio |
| `tenant.deleted` | `tenant_id` | Tenant deletado | Deleta usu√°rios, recursos, categorias e reservas |

#### Consumer Groups Implementados

**user-service**
- Consome `booking-events`:
  - `handle_booking_created`: Processa novas reservas para envio de notifica√ß√µes
  - `handle_booking_cancelled`: Gerencia cancelamentos e notifica√ß√µes
  - `handle_booking_status_changed`: Reage a mudan√ßas de status
- Consome `deletion-events`:
  - `handle_tenant_deleted`: Deleta todos os usu√°rios do tenant

**resource-service**
- Consome `booking-events`:
  - `handle_booking_created`: Atualiza m√©tricas e invalida cache de disponibilidade
  - `handle_booking_cancelled`: Libera slots e atualiza estat√≠sticas
  - `handle_booking_updated`: Reprocessa disponibilidade se hor√°rio mudou
- Consome `deletion-events`:
  - `handle_tenant_deleted`: Deleta recursos e categorias do tenant

**booking-service**
- Consome `deletion-events`:
  - `handle_resource_deleted`: Cancela reservas do recurso deletado
  - `handle_user_deleted`: Cancela reservas do usu√°rio deletado
  - `handle_tenant_deleted`: Deleta todas as reservas do tenant

#### Vantagens da Arquitetura

‚úÖ **Desacoplamento**: Booking Service n√£o precisa conhecer consumers  
‚úÖ **Escalabilidade**: M√∫ltiplos workers no mesmo consumer group  
‚úÖ **Confiabilidade**: Consumer groups garantem processamento √∫nico  
‚úÖ **Recupera√ß√£o**: Mensagens pendentes s√£o reprocessadas no startup  
‚úÖ **Rastreabilidade**: Logs estruturados de cada evento processado  

#### Monitoramento

```bash
# Total de eventos publicados
docker exec redis redis-cli XLEN booking-events
docker exec redis redis-cli XLEN deletion-events

# Status dos consumer groups
docker exec redis redis-cli XINFO GROUPS booking-events
docker exec redis redis-cli XINFO GROUPS deletion-events

# Mensagens pendentes (n√£o processadas)
docker exec redis redis-cli XPENDING booking-events user-service
docker exec redis redis-cli XPENDING deletion-events booking-service

# Ver √∫ltimos eventos
docker exec redis redis-cli XRANGE booking-events - + COUNT 10
docker exec redis redis-cli XRANGE deletion-events - + COUNT 10

# Logs de consumers
docker logs user 2>&1 | grep -i "event\|booking\|deletion"
docker logs resource 2>&1 | grep -i "event\|booking\|deletion"
docker logs booking 2>&1 | grep -i "event\|deletion"
```

#### Documenta√ß√£o Detalhada

Para documenta√ß√£o t√©cnica completa sobre a arquitetura event-driven, consulte:
- **[docs/EVENT_ARCHITECTURE.md](docs/EVENT_ARCHITECTURE.md)**: Guia completo com componentes, fluxos, monitoramento, troubleshooting e boas pr√°ticas.

#### Extensibilidade

Para adicionar novos consumers:

1. Registre handlers em `app/main.py`:
```python
import os
import logging
from shared import EventConsumer

logger = logging.getLogger(__name__)

consumer = EventConsumer(
    redis_url=os.getenv("REDIS_URL"),
    stream_name="booking-events",
    group_name="meu-servico",
    consumer_name="worker-1"
)

async def handle_booking_created(event_type: str, payload: dict):
    logger.info(f"Processando {event_type}: {payload}")
    # sua l√≥gica aqui

consumer.register_handler("booking.created", handle_booking_created)
```

2. Inicie consumer no lifespan:
```python
import asyncio
from contextlib import asynccontextmanager
from fastapi import FastAPI
from shared import cleanup_consumer

@asynccontextmanager
async def app_lifespan(app: FastAPI):
    consumer_task = asyncio.create_task(consumer.start())
    yield
    await cleanup_consumer(consumer, consumer_task, logger)
```

### Health Checks e Monitoramento

Todos os servi√ßos exp√µem endpoints de health check para monitoramento Docker/Kubernetes:

#### Endpoints Dispon√≠veis

**`GET /health`** - Health Check B√°sico
- Sempre retorna `200 OK` se o servi√ßo est√° rodando
- N√£o verifica depend√™ncias (use `/ready` para isso)
- Resposta:
  ```json
  {
    "status": "ok",
    "service": "user",
    "timestamp": "2025-01-15T10:30:00Z"
  }
  ```

**`GET /ready`** - Readiness Check
- Verifica se o servi√ßo est√° pronto para receber tr√°fego
- Verifica depend√™ncias: Database (obrigat√≥rio) e Redis (opcional)
- Retorna `200 OK` se tudo est√° saud√°vel, `503 Service Unavailable` se alguma depend√™ncia falhou
- Resposta (sucesso):
  ```json
  {
    "status": "ready",
    "service": "user",
    "timestamp": "2025-01-15T10:30:00Z",
    "checks": {
      "database": true,
      "redis": true
    }
  }
  ```
- Resposta (falha):
  ```json
  {
    "status": "not_ready",
    "service": "user",
    "timestamp": "2025-01-15T10:30:00Z",
    "checks": {
      "database": false,
      "redis": true
    }
  }
  ```

#### Uso com Docker Compose

Os servi√ßos j√° est√£o configurados com healthchecks no `docker-compose.yml`:
- Verifica `/ready` a cada 10 segundos
- Timeout de 5 segundos
- 3 tentativas antes de marcar como unhealthy
- Per√≠odo inicial de 30 segundos para inicializa√ß√£o

```bash
# Verificar status dos healthchecks
docker compose ps

# Ver logs de healthcheck de um servi√ßo
docker compose logs user | grep health
```

#### Uso com Kubernetes

Configure probes no seu deployment:

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 30
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /ready
    port: 8000
  initialDelaySeconds: 30
  periodSeconds: 5
```

#### Testando Manualmente

```bash
# Health check b√°sico
curl http://localhost:8000/health

# Readiness check (verifica depend√™ncias)
curl http://localhost:8000/ready

# Com autentica√ß√£o (se necess√°rio)
curl -H "Authorization: Bearer $TOKEN" http://localhost:8000/ready
```

### Testes automatizados
- `pytest` configurado para cada servi√ßo com bancos SQLite isolados.
- **Booking**: ciclo completo de reservas, conflitos de hor√°rio, valida√ß√µes de janelas de anteced√™ncia/cancelamento, flag `can_cancel` e testes de handlers de cascata (resource.deleted, user.deleted, tenant.deleted).
- **Resource**: fluxo CRUD de categorias e recursos, c√°lculo de disponibilidade com slots, bloqueio de conflitos e teste de handler tenant.deleted.
- **Tenant**: configura√ß√µes organizacionais, valida√ß√µes de hor√°rio comercial e labels customizadas.
- **User**: cria√ß√£o multi-tenant, permiss√µes, valida√ß√µes de email e teste de handler tenant.deleted.
- **Event Consumers**: testes de handlers de eventos (booking.created, booking.cancelled, booking.status_changed).
- **Deletion Consumers**: testes completos de cascata via eventos - 11 testes cobrindo todos os cen√°rios de dele√ß√£o.
- **Shared**: testes do EventConsumer, EventPublisher e utilit√°rios compartilhados.
- Executar toda a su√≠te: `.venv/bin/pytest`
- Executar servi√ßo espec√≠fico: `.venv/bin/pytest services/booking/tests`
- Testes usam `@pytest.mark.anyio` para fun√ß√µes async (consist√™ncia com FastAPI/anyio)

### Startup compartilhado
- Utilit√°rio `shared.startup.database_lifespan_factory` registra lifespan async com tentativas e logs para cria√ß√£o de tabelas.
- Todos os servi√ßos usam essa f√°brica em `app/main.py`, evitando duplica√ß√£o de c√≥digo e warnings de API deprecada.

### Migra√ß√µes (Alembic)
- Cada servi√ßo possui `alembic.ini` e diret√≥rio `alembic/` pr√≥prios.
- Execu√ß√£o em containers:
	- `docker compose run --rm tenant alembic upgrade head`
	- `docker compose run --rm user alembic upgrade head`
	- `docker compose run --rm resource alembic upgrade head`
	- `docker compose run --rm booking alembic upgrade head`
- Execu√ß√£o local: garantir `PYTHONPATH` apontando para `shared` + servi√ßo antes de rodar Alembic.

### Configura√ß√£o local do backend

#### Com Docker Compose (recomendado)
```bash
docker compose build        # builda todos os servi√ßos (deps atualizadas)
docker compose up           # sobe postgres, redis, servi√ßos e gateway
docker compose down         # desmonta ambiente
docker compose up --build   # rebuild r√°pido quando muda requirements/Dockerfile
docker compose up --build --force-recreate # rebuilda tudo (mais adequado para novas dep.)
```
- O compose injeta automaticamente vari√°veis cruzadas (`TENANT_SERVICE_URL`, `RESERVATION_SERVICE_URL`) para que os servi√ßos consultem configura√ß√µes e conflitos em tempo real.

#### Ambiente local sem Docker
1. Crie e ative um virtualenv (ou utilize `.venv`): `python3 -m venv .venv && source .venv/bin/activate`.
2. Instale depend√™ncias m√≠nimas (ex.: `pip install fastapi uvicorn sqlalchemy alembic httpx` para o servi√ßo de bookings).
3. Exporte o `PYTHONPATH` apontando para `services/shared` e para o servi√ßo desejado:
	```bash
	export PYTHONPATH="$(pwd)/services/shared:$(pwd)/services/booking"
	```
4. Rode as migra√ß√µes se necess√°rio (`alembic upgrade head`).
5. Inicie o servi√ßo com `uvicorn app.main:app --reload --port 8000` a partir da pasta do servi√ßo.
6. Configure as URLs necess√°rias para integra√ß√µes entre servi√ßos:
	```bash
	export TENANT_SERVICE_URL="http://localhost:8001"
	export RESOURCE_SERVICE_URL="http://localhost:8002/resources"
	export USER_SERVICE_URL="http://localhost:8003/users"
	export BOOKING_SERVICE_URL="http://localhost:8004/bookings"
	```
	> **Nota**: Os servi√ßos adicionam automaticamente os prefixes corretos (ex: `/tenants` para tenant service).
7. Repita o processo para cada microservi√ßo em portas diferentes caso queira o ecossistema completo.

### ‚öôÔ∏è Configura√ß√£o de Vari√°veis de Ambiente

O projeto utiliza vari√°veis de ambiente para gerenciar credenciais e configura√ß√µes sens√≠veis. **Nunca commite o arquivo `.env` no git** - ele cont√©m credenciais e est√° no `.gitignore`.

#### Setup Inicial

1. **Copie o arquivo de exemplo**:
   ```bash
   cp .env.example .env
   ```

2. **Configure as vari√°veis** no arquivo `.env`:
   - Edite `.env` e configure valores apropriados para seu ambiente
   - Em produ√ß√£o, use senhas fortes e gere uma `SECRET_KEY` segura:
     ```bash
     openssl rand -hex 64
     ```

3. **Valide sua configura√ß√£o**:
   ```bash
   ./scripts/validate_env.sh
   ```

#### Vari√°veis Principais

| Vari√°vel | Descri√ß√£o | Obrigat√≥ria | Padr√£o (Dev) |
|----------|-----------|-------------|--------------|
| `POSTGRES_USER` | Usu√°rio do PostgreSQL | ‚úÖ | `user` |
| `POSTGRES_PASSWORD` | Senha do PostgreSQL | ‚úÖ | `password` |
| `POSTGRES_DB_USER` | Nome do banco do servi√ßo User | ‚úÖ | `userdb` |
| `POSTGRES_DB_TENANT` | Nome do banco do servi√ßo Tenant | ‚úÖ | `tenantdb` |
| `POSTGRES_DB_RESOURCE` | Nome do banco do servi√ßo Resource | ‚úÖ | `resourcedb` |
| `POSTGRES_DB_BOOKING` | Nome do banco do servi√ßo Booking | ‚úÖ | `bookingdb` |
| `REDIS_URL` | URL de conex√£o com Redis | ‚úÖ | `redis://redis:6379` |
| `SECRET_KEY` | Chave secreta para JWT | ‚úÖ | (gerar com `openssl rand -hex 64`) |
| `JWT_ALGORITHM` | Algoritmo JWT | ‚úÖ | `HS512` |
| `ACCESS_TOKEN_EXPIRE_HOURS` | Expira√ß√£o do token (horas) | ‚úÖ | `24` |
| `TENANT_SERVICE_URL` | URL do servi√ßo Tenant | ‚úÖ | `http://tenant:8000` |
| `RESOURCE_SERVICE_URL` | URL do servi√ßo Resource | ‚úÖ | `http://resource:8000` |
| `USER_SERVICE_URL` | URL do servi√ßo User | ‚úÖ | `http://user:8000` |
| `BOOKING_SERVICE_URL` | URL do servi√ßo Booking | ‚úÖ | `http://booking:8000` |

#### URLs de Banco de Dados

As URLs de banco de dados s√£o constru√≠das automaticamente a partir das vari√°veis individuais:
```
postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db_<service>:5432/${POSTGRES_DB_<SERVICE>}
```

Voc√™ tamb√©m pode definir URLs completas diretamente:
- `USER_DATABASE_URL`
- `TENANT_DATABASE_URL`
- `RESOURCE_DATABASE_URL`
- `BOOKING_DATABASE_URL`

#### Seguran√ßa em Produ√ß√£o

‚ö†Ô∏è **IMPORTANTE**: Em produ√ß√£o:

1. **Nunca use valores padr√£o**: Defina todas as vari√°veis explicitamente
2. **Use senhas fortes**: Gere senhas seguras para `POSTGRES_PASSWORD`
3. **Gere SECRET_KEY segura**: Use `openssl rand -hex 64` para gerar uma chave de 64 bytes
4. **Configure ENVIRONMENT**: Defina `ENVIRONMENT=production` para ativar valida√ß√µes rigorosas
5. **Valide antes de deploy**: Execute `./scripts/validate_env.sh` antes de fazer deploy

O c√≥digo valida automaticamente valores inseguros em produ√ß√£o e lan√ßa erros se detectar:
- Senhas padr√£o (`password`, `123456`, etc.)
- SECRET_KEY padr√£o ou muito curta
- URLs de banco com credenciais padr√£o

#### Valida√ß√£o Autom√°tica

O script `scripts/validate_env.sh` valida:
- ‚úÖ Todas as vari√°veis obrigat√≥rias est√£o definidas
- ‚úÖ Formato correto das URLs de banco de dados
- ‚úÖ Aus√™ncia de valores padr√£o inseguros
- ‚úÖ SECRET_KEY tem tamanho adequado

Execute ap√≥s configurar `.env`:
```bash
./scripts/validate_env.sh
```

#### Docker Compose

O `docker-compose.yml` carrega automaticamente vari√°veis do `.env` usando `env_file: .env`. Todos os servi√ßos e bancos de dados PostgreSQL usam essas vari√°veis.

Para usar um arquivo `.env` diferente:
```bash
docker compose --env-file .env.production up
```

### üîß Pipeline CI (GitHub Actions)

O pipeline de CI executa automaticamente as seguintes etapas em cada Pull Request aberto, atualizado ou com novos commits para a branch main:

- Lint (Ruff): verifica o estilo e poss√≠veis erros de c√≥digo em todo o backend.

- Testes por servi√ßo: roda a su√≠te de testes de cada microsservi√ßo separadamente (tenant, resource, reservation, user).

- Coverage Report: gera relat√≥rios de cobertura (pytest --cov) para cada servi√ßo e disponibiliza como artifact no GitHub Actions.

- Valida√ß√£o dos Dockerfiles: executa docker compose build para garantir que todas as imagens Docker continuam buildando corretamente.

### TODO

#### üî¥ Seguran√ßa e Infraestrutura
- [ ] **Hash seguro de senhas**: Substituir implementa√ß√£o placeholder em `user/app/routers/crud.py` por `passlib[bcrypt]` ou `argon2-cffi`.
- [x] **Vari√°veis de ambiente**: Extrair credenciais hardcoded do `docker-compose.yml` para `.env` (postgres passwords, redis). ‚úÖ Implementado com valida√ß√£o autom√°tica e testes.
- [ ] **Rate limiting**: Configurar limites por IP/tenant no Nginx usando `limit_req_zone` e `limit_req`.
- [ ] **CORS configur√°vel**: Adicionar configura√ß√£o de CORS por ambiente (dev permite `*`, prod restringe dom√≠nios).

#### üü° Observabilidade e Qualidade
- [x] **Health checks em servi√ßos**: Adicionar endpoints `/health` e `/ready` em cada FastAPI app para monitoramento Docker/Kubernetes. ‚úÖ Implementado com verifica√ß√£o de Database e Redis.
- [ ] **Logging estruturado**: Padronizar logs JSON com contexto (tenant_id, request_id, trace_id) usando `structlog` ou `python-json-logger`.
- [ ] **M√©tricas (Prometheus)**: Expor `/metrics` com contadores de requests, lat√™ncias e erros via `prometheus-fastapi-instrumentator`.
- [ ] **Testes de integra√ß√£o**: Criar su√≠te validando fluxo completo (tenant settings ‚Üí disponibilidade ‚Üí cria√ß√£o de booking com conflitos).
- [ ] **Coverage reports**: Configurar `pytest-cov` para gerar relat√≥rios HTML e manter cobertura acima de 80%.
- [ ] **Lint e formata√ß√£o**: Adicionar `ruff` ou `black + isort + flake8` em pre-commit hooks e CI.

#### üü¢ Funcionalidades e Evolu√ß√£o
- [x] **Consumidores de eventos**: Implementado com Redis Streams e Consumer Groups. User e Resource services consomem eventos de booking. Booking service consome eventos de dele√ß√£o (resource.deleted, user.deleted, tenant.deleted).
- [x] **Cascata de dele√ß√µes via eventos**: Sistema completo implementado - ao deletar tenant/user/resource, eventos s√£o propagados e consumers executam dele√ß√µes em cascata automaticamente.
- [ ] **Notifica√ß√µes por email/SMS**: Integrar com provedor externo (SendGrid, Twilio) nos handlers de eventos.
- [ ] **Audit trail**: Criar consumer dedicado para persistir hist√≥rico completo de eventos em banco separado.
- [ ] **Webhooks para tenants**: Permitir configura√ß√£o de URLs para receber eventos via HTTP POST.
- [ ] **Autentica√ß√£o centralizada**: Adicionar servi√ßo de auth com JWT (access + refresh tokens), scopes por tenant e middleware de valida√ß√£o.
- [ ] **Cache Redis**: Cachear `OrganizationSettings` e disponibilidade de recursos com TTL configur√°vel.
- [ ] **Recurring bookings**: Implementar l√≥gica de recorr√™ncia usando `recurring_pattern` (di√°rio, semanal, mensal).
- [ ] **Relat√≥rios e analytics**: Endpoints de estat√≠sticas (taxa de ocupa√ß√£o, bookings por categoria, cancelamentos) respeitando pol√≠ticas do tenant.
- [ ] **Soft delete aprimorado**: Unificar estrat√©gia de exclus√£o l√≥gica (usar `deleted_at` timestamp em vez de m√∫ltiplos `is_active`).
- [x] **Corre√ß√£o do availability_schedule**: Bug corrigido no booking service - formato do schedule era `{"monday": [...]}` mas o c√≥digo procurava por `{"schedule": [...]}`. Agora bookings podem ser criadas corretamente respeitando a disponibilidade dos recursos.

#### üõ†Ô∏è Melhorias T√©cnicas
- [ ] **Requirements files**: Criar `requirements.txt` por servi√ßo (substituir `RUN pip install` inline nos Dockerfiles).
- [ ] **Database migrations CLI**: Script helper para rodar todas as migra√ß√µes de uma vez (`./migrate.sh all` ou `make migrate`).
- [ ] **Documenta√ß√£o de arquitetura**: Adicionar diagramas (C4, sequence) mostrando comunica√ß√£o entre servi√ßos e fluxo de eventos.
- [ ] **Error handling padronizado**: Criar middleware global para transformar exce√ß√µes em respostas JSON consistentes com trace_id.
- [ ] **Dependency injection avan√ßada**: Avaliar uso de `dependency-injector` para gerenciar settings providers e clientes externos.
